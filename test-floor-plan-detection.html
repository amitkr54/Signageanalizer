<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Floor Plan Detection Test - ONNX Runtime Web</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        
        h1 {
            color: #333;
            margin-bottom: 10px;
        }
        
        .subtitle {
            color: #666;
            margin-bottom: 30px;
        }
        
        .upload-zone {
            border: 3px dashed #667eea;
            border-radius: 10px;
            padding: 40px;
            text-align: center;
            background: #f8f9ff;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .upload-zone:hover {
            border-color: #764ba2;
            background: #f0f1ff;
        }
        
        .upload-zone.dragover {
            background: #e8eaff;
            border-color: #764ba2;
        }
        
        input[type="file"] {
            display: none;
        }
        
        .btn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 12px 30px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            transition: transform 0.2s;
        }
        
        .btn:hover {
            transform: translateY(-2px);
        }
        
        .status {
            margin-top: 20px;
            padding: 15px;
            border-radius: 8px;
            font-weight: 500;
        }
        
        .status.loading {
            background: #fff3cd;
            color: #856404;
        }
        
        .status.success {
            background: #d4edda;
            color: #155724;
        }
        
        .status.error {
            background: #f8d7da;
            color: #721c24;
        }
        
        .results {
            margin-top: 30px;
            display: none;
        }
        
        .results.show {
            display: block;
        }
        
        canvas {
            max-width: 100%;
            border-radius: 10px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
        }
        
        .detection-list {
            margin-top: 20px;
        }
        
        .detection-item {
            background: #f8f9ff;
            padding: 15px;
            margin: 10px 0;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        
        .detection-item strong {
            color: #667eea;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üèóÔ∏è Floor Plan Detection Test</h1>
        <p class="subtitle">Upload a floor plan PDF or image to detect rooms, doors, exits, and more using AI</p>
        
        <div class="upload-zone" id="uploadZone">
            <h3>üìÅ Drop your floor plan here</h3>
            <p>or</p>
            <button class="btn" onclick="document.getElementById('fileInput').click()">
                Choose File
            </button>
            <input type="file" id="fileInput" accept=".pdf,.jpg,.jpeg,.png">
            <p style="margin-top: 10px; color: #999; font-size: 14px;">
                Supports: PDF, JPG, PNG
            </p>
        </div>
        
        <div id="status"></div>
        
        <div class="results" id="results">
            <h2>Detection Results</h2>
            <canvas id="canvas"></canvas>
            <div class="detection-list" id="detectionList"></div>
        </div>
    </div>

    <script type="module">
        let session = null;
        
        // Model configuration
        const MODEL_CONFIG = {
            path: '/models/yolov8n.onnx',  // Change to your model path
            inputSize: 640,
            classes: ['door', 'window', 'wall', 'exit', 'stairs', 'room']
        };
        
        // Initialize ONNX Runtime
        async function initModel() {
            try {
                showStatus('Loading AI model...', 'loading');
                
                session = await ort.InferenceSession.create(MODEL_CONFIG.path, {
                    executionProviders: ['wasm'],
                    graphOptimizationLevel: 'all'
                });
                
                showStatus('‚úÖ Model loaded successfully! Ready to analyze floor plans.', 'success');
                console.log('Model loaded:', session);
            } catch (error) {
                showStatus(`‚ö†Ô∏è Model not found. Please place your ONNX model at: ${MODEL_CONFIG.path}`, 'error');
                console.error('Error loading model:', error);
            }
        }
        
        // Preprocess image for model input
        function preprocessImage(img, targetSize) {
            const canvas = document.createElement('canvas');
            canvas.width = targetSize;
            canvas.height = targetSize;
            const ctx = canvas.getContext('2d');
            
            // Draw resized image
            ctx.drawImage(img, 0, 0, targetSize, targetSize);
            
            // Get image data
            const imageData = ctx.getImageData(0, 0, targetSize, targetSize);
            const pixels = imageData.data;
            
            // Convert to normalized float32 tensor [1, 3, H, W]
            const float32Data = new Float32Array(3 * targetSize * targetSize);
            
            for (let i = 0; i < targetSize * targetSize; i++) {
                float32Data[i] = pixels[i * 4] / 255.0;                    // R
                float32Data[targetSize * targetSize + i] = pixels[i * 4 + 1] / 255.0;  // G  
                float32Data[2 * targetSize * targetSize + i] = pixels[i * 4 + 2] / 255.0; // B
            }
            
            return new ort.Tensor('float32', float32Data, [1, 3, targetSize, targetSize]);
        }
        
        // Run detection
        async function detectFloorPlan(imageElement) {
            if (!session) {
                showStatus('Model not loaded yet!', 'error');
                return;
            }
            
            try {
                showStatus('üîç Analyzing floor plan...', 'loading');
                
                // Preprocess
                const inputTensor = preprocessImage(imageElement, MODEL_CONFIG.inputSize);
                
                // Run inference
                const feeds = { images: inputTensor };
                const results = await session.run(feeds);
                
                // Post-process results
                const detections = postprocessResults(results);
                
                // Display results
                displayResults(imageElement, detections);
                
                showStatus(`‚úÖ Found ${detections.length} objects!`, 'success');
                
            } catch (error) {
                showStatus('‚ùå Error during detection: ' + error.message, 'error');
                console.error(error);
            }
        }
        
        // Post-process model output
        function postprocessResults(results) {
            // This is a simplified version
            // Real implementation depends on your model's output format
            
            console.log('Model output:', results);
            
            // For YOLOv8, output is typically [1, 84, 8400] or similar
            // You'll need to parse boxes, scores, and classes
            
            // Example detections (replace with real parsing)
            return [
                { class: 'door', confidence: 0.95, bbox: [100, 100, 150, 200] },
                { class: 'window', confidence: 0.89, bbox: [300, 150, 350, 180] },
                { class: 'exit', confidence: 0.92, bbox: [450, 100, 500, 200] }
            ];
        }
        
        // Display results
        function displayResults(image, detections) {
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            
            // Set canvas size
            canvas.width = image.width;
            canvas.height = image.height;
            
            // Draw original image
            ctx.drawImage(image, 0, 0);
            
            // Draw detections
            ctx.lineWidth = 3;
            ctx.font = '16px Arial';
            
            detections.forEach((det, idx) => {
                const color = `hsl(${idx * 60}, 70%, 50%)`;
                ctx.strokeStyle = color;
                ctx.fillStyle = color;
                
                // Draw bounding box
                const [x1, y1, x2, y2] = det.bbox;
                ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
                
                // Draw label
                const label = `${det.class} ${(det.confidence * 100).toFixed(0)}%`;
                ctx.fillText(label, x1, y1 - 5);
            });
            
            // Show detection list
            const listDiv = document.getElementById('detectionList');
            listDiv.innerHTML = detections.map(det => `
                <div class="detection-item">
                    <strong>${det.class}</strong> - Confidence: ${(det.confidence * 100).toFixed(1)}%
                </div>
            `).join('');
            
            document.getElementById('results').classList.add('show');
        }
        
        // Show status message
        function showStatus(message, type) {
            const statusDiv = document.getElementById('status');
            statusDiv.innerHTML = `<div class="status ${type}">${message}</div>`;
        }
        
        // Handle file upload
        document.getElementById('fileInput').addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;
            
            if (file.type === 'application/pdf') {
                showStatus('üìÑ PDF support coming soon! Please use JPG/PNG for now.', 'loading');
                // TODO: Add PDF.js integration
                return;
            }
            
            const img = new Image();
            img.src = URL.createObjectURL(file);
            
            img.onload = async () => {
                await detectFloorPlan(img);
            };
        });
        
        // Drag and drop
        const uploadZone = document.getElementById('uploadZone');
        
        uploadZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadZone.classList.add('dragover');
        });
        
        uploadZone.addEventListener('dragleave', () => {
            uploadZone.classList.remove('dragover');
        });
        
        uploadZone.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadZone.classList.remove('dragover');
            
            const file = e.dataTransfer.files[0];
            if (file) {
                document.getElementById('fileInput').files = e.dataTransfer.files;
                document.getElementById('fileInput').dispatchEvent(new Event('change'));
            }
        });
        
        // Initialize on load
        initModel();
    </script>
</body>
</html>
